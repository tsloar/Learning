---
title: "Grouped summaries with summaries ()"
author: "Tetiana Matviichuk"
date: "26 06 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Loading libraries
```{r, message = FALSE}
library(tidyverse)
library(nycflights13)
```

# How to explore the relationship between the distance and average delay for each location?



There are three steps to prepare this data:

1. Group flights by destination.

2. Summarise to compute distance, average delay, and number of flights.

3. Filter to remove noisy points and Honolulu airport, which is almost twice as far away as the next closest airport.

### summarize() for data frame
It collapses a data frame to a single row:

```{r}
summarise(flights, delay = mean(dep_delay, na.rm = TRUE))
```

But it is more useful with group_by():
```{r}
by_day <- group_by(flights, year, month, day)
summarise(by_day, delay = mean(dep_delay, na.rm = TRUE))
```

### Combining multiple operations with the pipe

```{r}
by_dest <- flights %>%
        group_by(dest) %>%
        summarise(
                  count = n(),
                  dist = mean(distance, na.rm = TRUE),
                  delay = mean(arr_delay, na.rm = TRUE)
                  ) %>%
        filter(count > 20, dest != "HNL")  #to ignore data with small observations

```

### Presenting plot. 

It looks like delays increase with distance up to ~750 miles and then decrease. Maybe as flights get longer there's more ability to make up delays in the air?

```{r}
ggplot(data = by_dest, mapping = aes(x = dist, y = delay)) +
        geom_point(aes(size = count, color = count), alpha = 1/3) +
        geom_smooth(se = FALSE)
```


## Missing Values

We could also tackle the problem by first removing the cancelled flights.

```{r}

not_cancelled <- flights %>% 
  filter(!is.na(dep_delay), !is.na(arr_delay))

not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(mean = mean(dep_delay))

```

How many are cancelled flights?

```{r}
cancelled <- flights %>%
        filter(is.na(dep_delay), is.na(arr_delay))
cancelled[which(cancelled$dep_delay == FALSE), ]
cancelled %>%
        group_by(tailnum) %>%
        summarise(
                count = n()
                )
summary(cancelled)
```


### Counts

Whenever you do any aggregation, it’s always a good idea to include either a count (n()), or a count of non-missing values (sum(!is.na(x))). That way you can check that you’re not drawing conclusions based on very small amounts of data. 

```{r}
delays <- flights %>%
        group_by(tailnum) %>%
        summarise(
                delay = mean(arr_delay)
        )
head(delays, 20)

ggplot(data = delays, mapping = aes(x = delay)) +
        geom_freqpoly(binwidth = 10)
```

But we can get more insight if we draw a scatterplot of number of flights vs. average delay:
```{r}
delays <- not_cancelled%>%
  group_by(tailnum) %>%
  summarise(
    count = n(),
    average_delay = mean(arr_delay, na.rm= TRUE)
  )

ggplot(data = delays, mapping = aes(x = count, y = average_delay)) +
  geom_point(aes(color = count), alpha = 1/10)
```


When looking at this sort of plot, it’s often useful to filter out the groups with the smallest numbers of observations, so you can see more of the pattern and less of the extreme variation in the smallest groups.

```{r}
delays %>%
  filter(count > 25) %>%
  ggplot(mapping = aes(x = count, y = average_delay)) +
  geom_point(aes(color = count), alpha = 1/10)


```


**RStudio tip**: a useful keyboard shortcut is **Cmd/Ctrl + Shift + P**. This resends the previously sent chunk from the editor to the console. 


## Example on Lahman database 

There’s another common variation of this type of pattern. Let’s look at how the average performance of batters in baseball is related to the number of times they’re at bat. 

We will compute the batting average (number of hits / number of attempts) of every major league baseball player.

When plotting the skill of the batter (measured by the batting average, *ba*) against the number of opportunities to hit the ball (measured by at bat, *ab*), see two patterns:

1. As above, the variation in our aggregate decreases as we get more data points.

2. There’s a positive correlation between skill (ba) and opportunities to hit the ball (ab). This is because teams control who gets to play, and obviously they’ll pick their best players.

```{r}
library(Lahman)
library(dplyr)

batting <- Lahman::Batting
batters <- batting %>%
  group_by(playerID) %>%
  summarise(
    ba = sum(H, na.rm = T)/sum(AB, na.rm = T),
    ab = sum(AB, na.rm = T)
  )

batters %>%
  filter(ab > 100) %>%
  ggplot(mapping = aes(x = ab, y = ba)) +
  geom_point(aes(color = ab), alpha = 1/10) +
  geom_smooth(se = FALSE)

```

## Useful summary function

To be continued...
